<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>tcse-2020 - Staley&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Stanley&#039;s blog"><meta name="msapplication-TileImage" content="/img/marijuana.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Stanley&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="TCSE-2020 Learning to Rank for Collaborative Filtering前言這是一篇關於我在Mars Lab時發表於TCSE-2020的論文，首先要感謝邱志義教授以及學長Benny與我的partner Jim，總是在研究上給我許多的幫助以及啟發。這是一篇關於推薦系統的論文，有興趣的夥伴歡迎交流指教。"><meta property="og:type" content="blog"><meta property="og:title" content="tcse-2020"><meta property="og:url" content="http://stankisapig.github.io/2021/12/26/tcse-2020/"><meta property="og:site_name" content="Staley&#039;s Blog"><meta property="og:description" content="TCSE-2020 Learning to Rank for Collaborative Filtering前言這是一篇關於我在Mars Lab時發表於TCSE-2020的論文，首先要感謝邱志義教授以及學長Benny與我的partner Jim，總是在研究上給我許多的幫助以及啟發。這是一篇關於推薦系統的論文，有興趣的夥伴歡迎交流指教。"><meta property="og:locale" content="zh_TW"><meta property="og:image" content="http://stankisapig.github.io/gallery/thumbnails/tcse-2020/TCSE_title.jpg"><meta property="article:published_time" content="2021-12-26T21:44:09.000Z"><meta property="article:modified_time" content="2022-01-07T20:47:20.903Z"><meta property="article:author" content="stank"><meta property="article:tag" content="TCSE"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/thumbnails/tcse-2020/TCSE_title.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://stankisapig.github.io/2021/12/26/tcse-2020/"},"headline":"tcse-2020","image":["http://stankisapig.github.io/gallery/thumbnails/tcse-2020/TCSE_title.jpg"],"datePublished":"2021-12-26T21:44:09.000Z","dateModified":"2022-01-07T20:47:20.903Z","author":{"@type":"Person","name":"stank"},"publisher":{"@type":"Organization","name":"Staley's Blog","logo":{"@type":"ImageObject","url":"http://stankisapig.github.io/img/marijuana.png"}},"description":"TCSE-2020 Learning to Rank for Collaborative Filtering前言這是一篇關於我在Mars Lab時發表於TCSE-2020的論文，首先要感謝邱志義教授以及學長Benny與我的partner Jim，總是在研究上給我許多的幫助以及啟發。這是一篇關於推薦系統的論文，有興趣的夥伴歡迎交流指教。"}</script><link rel="canonical" href="http://stankisapig.github.io/2021/12/26/tcse-2020/"><link rel="icon" href="/img/marijuana.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/marijuana.png" alt="Staley&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="My GitHub" href="https://github.com/stankisapig"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="文章目錄" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜尋" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/gallery/thumbnails/tcse-2020/TCSE_title.jpg" alt="tcse-2020"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-12-26T21:44:09.000Z" title="12/26/2021, 9:44:09 PM">2021-12-26</time>發表</span><span class="level-item"><time dateTime="2022-01-07T20:47:20.903Z" title="1/7/2022, 8:47:20 PM">2022-01-07</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/studies/">studies</a></span><span class="level-item">28 分鐘讀完 (大約4194個字)</span></div></div><h1 class="title is-3 is-size-4-mobile">tcse-2020</h1><div class="content"><h2 id="TCSE-2020-Learning-to-Rank-for-Collaborative-Filtering"><a href="#TCSE-2020-Learning-to-Rank-for-Collaborative-Filtering" class="headerlink" title="TCSE-2020 Learning to Rank for Collaborative Filtering"></a>TCSE-2020 Learning to Rank for Collaborative Filtering</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>這是一篇關於我在Mars Lab時發表於TCSE-2020的論文，首先要感謝邱志義教授以及學長Benny與我的partner Jim，總是在研究上給我許多的幫助以及啟發。這是一篇關於推薦系統的論文，有興趣的夥伴歡迎交流指教。</p>
<span id="more"></span>

<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>推薦系統現在廣泛應用於各個領域甚至是我們生活之中，其中有兩大要素啟發了我們這次的實驗。<br>第一：<br>    為了實現推薦系統，我們可以很直觀地認為系統應推薦符合用戶期望的物品。然而，給定一組物品，過去的研究時常專注於“相關”或“不相關”的某些物品，而不是專注於物品對之間的偏好程度。這可能違反推薦系統的主要目的。<br>第二：<br>    leave-one-out evaluation protocol被廣泛應用如下：<br>    對於每個用戶，他們保留他/她最近的交互作為測試集，並利用剩餘的數據進行訓練。由於在評估過程中為每個用戶對所有項目進行排序太耗時，他們遵循通用策略，隨機抽取 100 個用戶未交互的項目，在 100 個項目中對測試項目進行排名。但是，每個用戶最近的交互項可能是也可能不是他們喜歡的，有可能用戶對最新項的真實評分很低，不應該被系統推薦；它會與評估設置的設計相衝突。</p>
<h2 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I. Introduction"></a>I. Introduction</h2><p>&emsp;&emsp;The recommendation system is used to predict the user’s “rating” or “preference” of items and can help people cope with complex preferences prediction problems. Collaborative filtering approaches build a model from a user’s past behavior (items previously purchased or numerical ratings given to those items) as well as similar decisions made by other users. This model is then used to predict or rate items that the user may have an interest in. Content-based filtering approaches utilize a series of discrete, pre-tagged characteristics of an item in order to recommend additional items with similar properties.</p>
<p>&emsp;&emsp;In 2017, Hseih et al. [1] proposed the collaborative metric learning (CML) which revealed the potential of inner product to model user-item relationships. They argued that the inner product violates the triangle inequality which is essential to model the fine-grained preference of users. Thus, the authors come up with a metric-based learning scheme that minimizes the distance between user and item vectors of positive interactions. Simultaneously, this scheme also learns user-user similarity and item-item similarity in the latent space. Their work demonstrates a highly competitive performance on many benchmark datasets.</p>
<p>&emsp;&emsp;However, in spite of the success of these works, they consist some weaknesses. Firstly, for implementing a recommender system, it is intuitively to consider that the system recommends the item that fits the expectation of the user. However, given a set of objects, they focus on the certain pairs of objects that are “relevant” or “irrelevant” instead of knowing the preference degree between pairs of objects. It may violate the main purpose of the recommender system. Secondly, the leave-one-out evaluation protocol is widely adopted as follows: For each user, they held-out his/her latest interaction as the test set and utilized the remaining data for training. Since it is too time-consuming to rank all items for every user during evaluation, they follow the common strategy that randomly samples 100 items that are not interacted by the user, ranking the test item among the 100 items. However, the latest interaction item of each user may or may not be the one they prefer, it is possible that the true rating of the latest item rated by the user is low, and should not be recommended by the system; it will conflict the design of the evaluation setup.</p>
<p>&emsp;&emsp;To solve the above problem, we propose a novel collaborative metric learning method with respect to the traditional collaborative filtering, which learns a metric space to represent not only the user’s preferences but also their similarities. We employ the triplet loss function in neural networks to train users’ preference ranking model. We care more about user preferences than whether users interact with the item. Moreover, we come up with a new leave-one-out evaluation methodology. Rather than using his/her latest interaction as the test set, we hold-out one highest rated item of each user according to the true ratings then randomly samples 100 items that are not interacted by the user, ranking the test item among the 100 items. This new methodology can retrieve the relevant item for the user and eliminate the conflict in the original evaluation. Experiment results show a great potential of our model compared to some state-of-the-art algorithms.</p>
<p>&emsp;&emsp;The remainder of this paper is organized as follows. In Section II, we introduced the background used in this paper. In Section III, we introduce our novel collaborative matric learning model. In Section IV, we compare our method to some state-of-the-art algorithms on MovieLens dataset. Finally, we conclude this paper in Section V.</p>
<h2 id="II-Background"><a href="#II-Background" class="headerlink" title="II. Background"></a>II. Background</h2><h3 id="A-Feedbacks"><a href="#A-Feedbacks" class="headerlink" title="A. Feedbacks"></a>A. Feedbacks</h3><p>&emsp;&emsp;In order to implement a recommender system, it requires substantial data provided by the user purposely or unpurposely, also known as feedbacks. Feedbacks can be divided into the explicit feedback and implicit feedback by the differences of its essence.</p>
<p>&emsp;&emsp;The explicit feedback directly shows the preferences of user, according to the opinion or score given to the item, usually formed as measurable indicators. Comparing to the explicit feedback, the implicit feedback is relatively blurry, it could be any slight action that user makes (e.g., clicks, browse, bookmarks). The definition of the implicit feedback can be described as follows:</p>
<!-- 

$$
y_{ui} =\left\{
\begin{aligned}
&1,if \quad interaction\<user_u, item_i\>exist\\
&0, otherwise
\end{aligned}
\right.
$$

 -->


$$
y_{ui} =\left\{
\begin{aligned}
&1,if \quad interaction < user_u, item_i > exist\\
&0, otherwise
\end{aligned}
\right.
$$


<p>where Y is the user-item interaction matrix.</p>
<p>&emsp;&emsp;Note that for the implicit feedback, a value of 0 does not necessarily imply negative feedback. In most cases, the user is unaware of the existence of the item and this forms the keystone of the recommendation problem, i.e., if the user did not rate an item or have no interaction with an item, we can’t be sure the relation between them.</p>
<h3 id="B-Triplet-Loss"><a href="#B-Triplet-Loss" class="headerlink" title="B. Triplet Loss"></a>B. Triplet Loss</h3><p>&emsp;&emsp;Triplet loss [2] is a widely used loss function in solving the optimization problem, it is even used to accomplish information retrieval tasks within different modalities in recent studies. Over all, triplet loss is a fine mapping technique and a good way to compute loss in the field of pattern recognition and cluster analysis. Figure 1 shows how triplet works.</p>
<p>&emsp;&emsp;Triplet includes an anchor point, a positive point and a negative point. Through an embedding architecture, inputs are embedded onto the new vector space, where the embedded result follows the triplet loss concept. During the learning phase, the positive point will be pulled toward the anchor point while the negative point will be push away from the anchor point. Note that in our work, the anchor point indicates the user, positive point indicates the item that user prefers more and the negative point indicates the item that user prefers less. Figure 2 and Figure 3 show the embedded status before and after the learning.</p>
<img src="https://drive.google.com/uc?export=view&id=1CvOgbndZEDKaSiJAjqUkQ44F_Tw_-4Ep" alt="Fig. 1. A sketch of triplet structure." width="70%" height="70%" style="display:block; margin:auto;">

<img src="https://drive.google.com/uc?export=view&id=188PnYQCQNww_muWAzCCnXUoyl6YA5qyO" alt="Fig. 2. Status before learning within the latent space." width="70%" height="70%" style="display:block; margin:auto;">

<img src="https://drive.google.com/uc?export=view&id=1jR5mAqFtzJWC3Nh1pyB7TblVrmgm-ezv" alt="Fig. 3. Status after learning within the latent space." width="70%" height="70%" style="display:block; margin:auto;">

<h3 id="C-Collaborative-Filtering-CF"><a href="#C-Collaborative-Filtering-CF" class="headerlink" title="C. Collaborative Filtering (CF)"></a>C. Collaborative Filtering (CF)</h3><p>&emsp;&emsp;Traditional CF algorithms [3] are based on the user similarity computed by heuristic, such as cosine similarity. Recommendations are made by aggregating the ratings of k-nearest users.</p>
<p>Matrix factorization (MF) [4] has been the most popular CF approach for a decade due to its remarkable performance. The original MF models are designed to model users’ feedback by mapping users and items to a latent space, such that user-item relationships can be inferred through their dot product in this latent space. To be more precise, let \(r_{jk}\) denote user <em>j</em>‘s rating to item <em>k</em>, we learn user vector \(u_j\) and item vector \(i_k\) such that their dot product \(u^T_j i_k\) approximate \(r_{jk}\) through the following formula:</p>

$$
min_{u_* i_*}
\sum_{r_{jk} \in K} 
(r_{jk}-u^T_j i_k)^2+
\theta_1 \Vert u_j \Vert + 
\theta_2 \Vert i_k \Vert
$$


<p>where <em>K</em> is the set of known ratings; \(\theta_1\) and \(\theta_2\) are hyperparameters that regularize the \(L^2\)-norm of \(u_*\) and \(i_*\).</p>
<h3 id="D-Leave-one-out"><a href="#D-Leave-one-out" class="headerlink" title="D. Leave-one-out"></a>D. Leave-one-out</h3><p>&emsp;&emsp;Leave-one-out is a common evaluation protocol in recent recommender system papers [5] [6] [7] [8]. It holds-out one data from the original dataset for testing and the rest remains for training. Specifically, for recommender systems, according to the rated items’ timestamps of each user, the most recent rated item is held-out as the test set and the remaining items for training. Since it is too time-consuming to rank all items for every user during evaluation, most studies follow the common strategy that randomly samples 100 items that are not interacted by the user and rank the test item among the 100 items. A sketch map of the leave-one-out evaluation protocol is shown in Figure 4.</p>
<img src="https://drive.google.com/uc?export=view&id=1TTRkTFDB1iCWvos_hvsG5KaRL7EZBjzD" alt="Fig. 4. Leave-one-out evaluation protocol." width="70%" height="70%" style="display:block; margin:auto;">

<h2 id="III-The-Proposed-Medel"><a href="#III-The-Proposed-Medel" class="headerlink" title="III. The Proposed Medel"></a>III. The Proposed Medel</h2><p>&emsp;&emsp;In this section, we introduce our novel collaborative matric learning model. The overall architecture is shown in Figure 5. Our model aims to map the user and item onto a latent space in which not only represents the user-user and item-item relationship but also the users’ preferences, so that the recommendation fits the users’ expectation. Let us begin with a simple high-level overview of our model:</p>
<ul>
<li>Before the data enters the embedding layer as input, a triplet \(\lt user , item^+ , item^- \gt\) has to be chosen from the user-item interaction matrix. We added a threshold <em>t</em> to the interaction matrix according to the true ratings. After a <em>user</em> is chosen, the corresponding \(item^+\) and \(item^-\) are then choosed under the condition that \(item^+\) has a true rating greater than <em>t</em>, in the meantime \(item^-\) either has a true rating lower than <em>t</em> or is a 0 in the interaction matrix.</li>
<li>\(\lt user , item^+ , item^- \gt\) is then converted to dense vector representations using an Embedding Layer. Output \(\lt u , i^+ , i^- \gt\) represents the user vector, positive item vector and negative item vector respectively.</li>
<li>Given \(\lt u , i^+ , i^- \gt\), our model maps users and items onto a latent space in which similar users are close to each other and so do similar items. Meanwhile, for each user, the items he/she prefers more are relatively closer than those he/she prefers less.</li>
<li>Our model optimizes for the triplet loss \( max ( 0 , (u-i^+)^2 - (u-i^-)^2 + \alpha ) \approx 0 \) using an optimizer with Tensorflow backend where \( \alpha \) is a margin we defined.</li>
</ul>
<img src="https://drive.google.com/uc?export=view&id=19gCJa-RNq4ElNId6X7zKXL32gLakL76r" alt="Fig. 5. Illustration of our proposed model architecture." width="70%" height="70%" style="display:block; margin:auto;">

<h3 id="A-Preprocessing"><a href="#A-Preprocessing" class="headerlink" title="A. Preprocessing"></a>A. Preprocessing</h3><p>&emsp;&emsp;In order to build our user-item interaction matrix, it is necessary that we parse the data from the dataset beforehand. Take the MovieLens dataset we employed for example, it provides the user contents, movie contents and the ratings. User contents and movie contents are for content-base [9] methods, for collaborative filtering [3], we concern the ratings instead. The ratings file contains the history ratings of movies that users rated through time. In this file, users and their corresponding movies are represented as IDs, ratings are represented as a number in the range of [10] [5] followed by the timestamps that ratings were given. By parsing the ratings file to the type we needed, we then build our user-item interaction for model input using the equation 3. An example of the ratings file is shown in Figure 6.</p>
<h3 id="B-Interaction-Matrix"><a href="#B-Interaction-Matrix" class="headerlink" title="B. Interaction Matrix"></a>B. Interaction Matrix</h3><p>&emsp;&emsp;Let <em>Y</em> be the user-item interaction matrix, <em>t</em> be the threshold for the true ratings. We build our user-item interaction matrix follows:</p>

$$
y_{ui} =\left\{
\begin{aligned}
&1,if \quad interaction < user_u, item_i > exist \quad and \quad r>t\\
&0, otherwise
\end{aligned}
\right.
$$


<p>where <em>r</em> denotes the true rating for item <em>i</em> rated by user <em>u</em>. An example of the user-item interaction matrix that built from Figure 6 is shown in Figure 7.</p>
<img src="https://drive.google.com/uc?export=view&id=1AnUQAdQnrxp3o8urIZca8fstHvI8ff5f" alt="Fig. 6. An example of the ratings file from dataset." width="70%" height="70%" style="display:block; margin:auto;">
<img src="https://drive.google.com/uc?export=view&id=1dcix-ax8OltrRC01UCXoLx3Xn03qK4vZ" alt="Fig. 7. An interaction matrix built from the ratings file in Figure 6." width="70%" height="70%" style="display:block; margin:auto;">

<h3 id="C-Embedding-Layer"><a href="#C-Embedding-Layer" class="headerlink" title="C. Embedding Layer"></a>C. Embedding Layer</h3><p>&emsp;&emsp;In this section we bring up how and why we do the embedding. For starters, there are two main reasons we choose to add in the embedding layer. First, due to the high dimensionality and sparsity of our data, in order to save resources and time, we adopt embedding instead of one-hot encoding. Second, every embedded vector within a neural network will be updated during the training phase. This leads us to reveal the similarities between embedded data in multidimensional space. The structure of the embedding lookup table is shown in Figure 8.<br>&emsp;&emsp;The embedding layer in our model accepts a triplet \(\lt user , item^+ , item^- \gt\) as an input which is chosen from <em>Y</em>. Inputs of users and items are represented as their ID. Through the embedding layer, their ID is converted into a <em>d</em> dimensional real-valued dense vector. The output of this layer is represented as \(\lt u , i^+ , i^- \gt\), which are the embedded vector of the user, positive item and negative item respectively.</p>
<img src="https://drive.google.com/uc?export=view&id=1f0b3eE-3DNOpyFW0hgB84DodMoHR1HfU" alt="Fig. 8. Embedding lookup table structure." width="70%" height="70%" style="display:block; margin:auto;">

<h3 id="D-Optimization-and-Learning"><a href="#D-Optimization-and-Learning" class="headerlink" title="D. Optimization and Learning"></a>D. Optimization and Learning</h3><p>&emsp;&emsp;In this section we introduce how the weight matric in MLP being updated, the objective function in our training scheme. We adopt the triplet loss for optimization and the loss is defined as follow:</p>


$$
L= \max ( 0 , (\hat{u}-\hat{i^+})^2 - (\hat{u}-\hat{i^-})^2 + \alpha )
$$



<p>where \( \alpha \) is the margin and the weight matrix in MLP is updated through iterations by minimizing <em>L</em>. An illustration of how the optimization and learning update the weight of each layer in our model is shown in Figure 9.</p>
<img src="https://drive.google.com/uc?export=view&id=1u1al8kgglyE2_6hKffubfbnoOeQcVK2W" alt="Fig. 9. An illustration of optimization and learning." width="70%" height="70%" style="display:block; margin:auto;">

<h3 id="E-New-Leave-one-out"><a href="#E-New-Leave-one-out" class="headerlink" title="E. New Leave-one-out"></a>E. New Leave-one-out</h3><p>&emsp;&emsp;In order to evaluate our model, we come up with a new leave-one-out methodology. We hold-out one highest rated item of each user according to the true ratings, then randomly samples 100 items that are not interacted by the user, ranking the test item among the 100 items. Figure 10shows an illustration of the new leave-one-out methodology proposed. With the new leave-one-out methodology, our model will be learned to rank high rated items for each user to top-k among other items and the recommendation is made according to the ranking results.</p>
<img src="https://drive.google.com/uc?export=view&id=1O7T_5jbAJSPs-F8JDf9_xKIeIxgyZXwT" alt="Fig. 10. Our new leave-one-out evaluation methodology." width="70%" height="70%" style="display:block; margin:auto;">

<h2 id="IV-Performance-Evaluation"><a href="#IV-Performance-Evaluation" class="headerlink" title="IV. Performance Evaluation"></a>IV. Performance Evaluation</h2><p>&emsp;&emsp;In this section, we evaluate our proposed model against other state-of-the-art algorithms and show the implement details along with the experimental result at the end of this section.</p>
<h3 id="A-Datasets-and-Environment"><a href="#A-Datasets-and-Environment" class="headerlink" title="A. Datasets and Environment"></a>A. Datasets and Environment</h3><p>&emsp;&emsp;MovieLens [11] is a widely adopted benchmark dataset for collaborative filtering in the application domain of recommending movies to users. We use three configurations of this benchmark dataset including MovieLens100K, MovieLens1M and MovieLens20M. The statistics of MovieLens datasets are reported in Table 1.<br>&emsp;&emsp;Totally we evaluate our proposed method on three datasets with diverse size and interaction densities. Experiments are implemented under Windows 10 with an Intel(R) Core(TM) i7-6700 CPU, up to 64GB RAM and a NVIDIA GeForce GTX 1080Ti GPU. For compile environment we use Keras package with Tensorflow backend under a 3.7 version of Python.</p>
<p><em>TABLE I.    The statistics of MovieLens Datasets</em></p>
<table>
<thead>
<tr>
<th align="left">Dataset</th>
<th align="right">Interactions</th>
<th align="right">#Users</th>
<th align="right">#Items</th>
<th align="right">%Density</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ML100K</td>
<td align="right">100K</td>
<td align="right">1K</td>
<td align="right">1.7K</td>
<td align="right">6.3</td>
</tr>
<tr>
<td align="left">ML1M</td>
<td align="right">1M</td>
<td align="right">6K</td>
<td align="right">4K</td>
<td align="right">4.2</td>
</tr>
<tr>
<td align="left">ML20M</td>
<td align="right">20M</td>
<td align="right">13K</td>
<td align="right">27K</td>
<td align="right">0.5</td>
</tr>
</tbody></table>
<h3 id="B-Baselines-and-Evaluation-Protocol"><a href="#B-Baselines-and-Evaluation-Protocol" class="headerlink" title="B. Baselines and Evaluation Protocol"></a>B. Baselines and Evaluation Protocol</h3><ul>
<li><strong>Multi-layered Perceptron (MLP)</strong> is the baseline using neural architecture in [5], which the authors proposed to model the relationships between users and items.</li>
<li><strong>Bayesian Personalized Ranking (BPR)</strong> [6] is one of the strong CF baseline in early years that minimizes \( \sum i \sum j , k - \log \sigma ( p_i^Tq_j - p_i^Tq_k ) + \lambda_1 \Vert p_i \Vert^2 + \lambda_2 \Vert q_j \Vert^2 \), where \( (p_i,q_j) \) is a positive interaction and \( (p_i,q_k) \) is a negative sample.</li>
<li><strong>Neural Matrix Factorization (NeuMF)</strong> is a framework that combine MF with MLP to predict the user item rating [5].</li>
</ul>
<p>&emsp;&emsp;For evaluation, we adopt our new leave-one-out evaluation methodology, i.e., the testing set comprises the highest rated item of all users. If there are same rating items, we randomly sample one within those items. Since it is too time consuming to rank all items for every user, we randomly sampled 100 items that have no interactions with the target user as [5][6] [7] [8] and rank the test item among these 100 items. Since our work is formulated as learning to rank, we determine the performance of our model based on the well-known normalized discounted cumulative gain (nDCG@10) [12] and Hit Ratio (H@10), where nDCG@10 represents the precision while H@10 represents the accuracy.</p>
<h3 id="C-Implement-Details"><a href="#C-Implement-Details" class="headerlink" title="C. Implement Details"></a>C. Implement Details</h3><p>&emsp;&emsp;By tuning the hyperparameters, we select the model which has the best performance through epochs. We obtain the result that model on the test set when an epoch ends and the model is saved when the current test result is better than previous, so the best model can be easily acquired when the training is finished. Models are trained for a maximum of 200 epochs with early stopping strategy [13]. The dimensionality of user and item embedding <em>d</em> is tuned amongst {10, 50, 100, 200}. Batch size during the training phase is tuned amongst {16, 64, 256, 1024} according to the number of trainable parameters. The learning rate is tuned amongst {0.17, 0.017, 0.0017, 0.00017}. Models are optimized using the Adam optimizer [14]. For the network architecture of the baselines, we follow the original setup in their studies respectively. The margin \( \alpha \) in our triplet loss function is tuned amongst {0.1, 0.2, 0.3, 0.4, 0.5} depending on the output distribution. Due to the output of our model is in certain dimensionality with normalized vector value, the value of \( \alpha \) doesn’t affect the result much, we simply choose \( \alpha \) that gives the best performance.<br>&emsp;&emsp;For each user, there are totally 100 items to rank during the testing phase including the ground-truth item. The test data is input to our model in a form of triplet as our model requires, after the testing triplet \(\lt test _userID , test _itemID , test _itemID \gt\) was input, the model outputs the latent vector representations of users and items. Since the position of negative item in the triplet means nothing during the testing phase, we simply replace it by repeating \(\lt test _itemID \gt\) in order to maintain the shape of our input. When the performance computation for each user ended, all H@10 and nDCG@10 will be added together and divide by the total user count to get the final result.</p>
<h3 id="D-Experimental-Results"><a href="#D-Experimental-Results" class="headerlink" title="D. Experimental Results"></a>D. Experimental Results</h3><p>&emsp;&emsp;The experiment results of our proposed model and baselines on three of the MovieLens [11] datasets are shown in Table II to Table VII. From the tables, we infer that some of the competitor baselines fail to obtain stable ranking results due to the variety of data characteristic in different datasets while our model maintains a stabler performance.<br>&emsp;&emsp;Table II and Table III show the evaluation result using the new leave-one-out methodology we proposed. Under the goal of finding potential high rated item for users, our model performs competitively on all datasets and obtains an outstanding performance on both H@10 and nDCG@10 among the baselines.<br>&emsp;&emsp;Table IV and Table V show the evaluation result using regular leave-one-out, in which the last timestamp item of each user is held-out for testing. Under this evaluation protocol, the best recommendation may not be made for each user. In order to make a contradiction, we also come up with an additional evaluation result by holding-out the lowest rated item for each user to test, the result is shown in Table IV and Table V.<br>&emsp;&emsp;To sum up, from Table II and Table VII, we can infer that our proposed model performs well when the high rated item is held-out for testing. It also indicates that we successfully rank the high rated item to top-k among other items. On the contrary, when the lowest rated item is held-out for testing, our proposed model performs badly due to making bad recommendations violates the purpose of our model.</p>
<p><em>TABLE II. H@10 Results on the Movielens Datasets. (High Rated)</em></p>
<table>
<thead>
<tr>
<th align="left">H@10</th>
<th align="right">#MLP</th>
<th align="right">#BPR</th>
<th align="right">#NeuMF</th>
<th align="right">#Ours</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ML100K</td>
<td align="right">65.12</td>
<td align="right">77.09</td>
<td align="right">82.82</td>
<td align="right">83.67</td>
</tr>
<tr>
<td align="left">ML1M</td>
<td align="right">59.64</td>
<td align="right">74.52</td>
<td align="right">86.18</td>
<td align="right">88.86</td>
</tr>
<tr>
<td align="left">ML20M</td>
<td align="right">78.90</td>
<td align="right">89.09</td>
<td align="right">96.09</td>
<td align="right">97.62</td>
</tr>
</tbody></table>
<p><em>TABLE III.    nDCG@10 Results on the Movielens Datasets. (High Rated)</em></p>
<table>
<thead>
<tr>
<th align="left">nDCG@10</th>
<th align="right">#MLP</th>
<th align="right">#BPR</th>
<th align="right">#NeuMF</th>
<th align="right">#Ours</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ML100K</td>
<td align="right">38.71</td>
<td align="right">50.57</td>
<td align="right">56.23</td>
<td align="right">60.91</td>
</tr>
<tr>
<td align="left">ML1M</td>
<td align="right">32.72</td>
<td align="right">49.46</td>
<td align="right">61.60</td>
<td align="right">66.03</td>
</tr>
<tr>
<td align="left">ML20M</td>
<td align="right">54.52</td>
<td align="right">52.37</td>
<td align="right">79.61</td>
<td align="right">82.39</td>
</tr>
</tbody></table>
<p><em>TABLE IV. H@10 Results on the Movielens Datasets. (Timestamp)</em></p>
<table>
<thead>
<tr>
<th align="left">H@10</th>
<th align="right">#MLP</th>
<th align="right">#BPR</th>
<th align="right">#NeuMF</th>
<th align="right">#Ours</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ML100K</td>
<td align="right">51.97</td>
<td align="right">64.26</td>
<td align="right">83.40</td>
<td align="right">81.44</td>
</tr>
<tr>
<td align="left">ML1M</td>
<td align="right">46.58</td>
<td align="right">62.17</td>
<td align="right">64.27</td>
<td align="right">63.44</td>
</tr>
<tr>
<td align="left">ML20M</td>
<td align="right">72.36</td>
<td align="right">95.22</td>
<td align="right">98.19</td>
<td align="right">96.64</td>
</tr>
</tbody></table>
<p><em>TABLE V. nDCG@10 Results on the Movielens Datasets. (Timestamp)</em></p>
<table>
<thead>
<tr>
<th align="left">nDCG@10</th>
<th align="right">#MLP</th>
<th align="right">#BPR</th>
<th align="right">#NeuMF</th>
<th align="right">#Ours</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ML100K</td>
<td align="right">32.85</td>
<td align="right">39.57</td>
<td align="right">59.30</td>
<td align="right">53.35</td>
</tr>
<tr>
<td align="left">ML1M</td>
<td align="right">30.16</td>
<td align="right">40.55</td>
<td align="right">45.18</td>
<td align="right">42.96</td>
</tr>
<tr>
<td align="left">ML20M</td>
<td align="right">53.20</td>
<td align="right">58.75</td>
<td align="right">77.10</td>
<td align="right">66.49</td>
</tr>
</tbody></table>
<p><em>TABLE VI. H@10 Results on the Movielens Datasets. (Low Rated)</em></p>
<table>
<thead>
<tr>
<th align="left">H@10</th>
<th align="right">#MLP</th>
<th align="right">#BPR</th>
<th align="right">#NeuMF</th>
<th align="right">#Ours</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ML100K</td>
<td align="right">46.82</td>
<td align="right">58.96</td>
<td align="right">66.70</td>
<td align="right">45.17</td>
</tr>
<tr>
<td align="left">ML1M</td>
<td align="right">40.30</td>
<td align="right">43.21</td>
<td align="right">60.03</td>
<td align="right">34.09</td>
</tr>
<tr>
<td align="left">ML20M</td>
<td align="right">65.45</td>
<td align="right">84.31</td>
<td align="right">93.65</td>
<td align="right">78.44</td>
</tr>
</tbody></table>
<p><em>TABLE VII. nDCG@10 Results on the Movielens Datasets. (Low Rated)</em></p>
<table>
<thead>
<tr>
<th align="left">nDCG@10</th>
<th align="right">#MLP</th>
<th align="right">#BPR</th>
<th align="right">#NeuMF</th>
<th align="right">#Ours</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ML100K</td>
<td align="right">27.01</td>
<td align="right">34.58</td>
<td align="right">40.40</td>
<td align="right">25.09</td>
</tr>
<tr>
<td align="left">ML1M</td>
<td align="right">22.17</td>
<td align="right">23.35</td>
<td align="right">35.49</td>
<td align="right">17.90</td>
</tr>
<tr>
<td align="left">ML20M</td>
<td align="right">47.51</td>
<td align="right">55.23</td>
<td align="right">68.34</td>
<td align="right">45.05</td>
</tr>
</tbody></table>
<h2 id="V-Conclusion"><a href="#V-Conclusion" class="headerlink" title="V. Conclusion"></a>V. Conclusion</h2><p>&emsp;&emsp;In this work, we employ the triplet loss in the neural network to optimize collaborative filtering and learn a latent space to represent the user-user similarity, item-item similarity and the user preference. We also come up with a new leave-one-out methodology to train and test our model to fit our hypothesis. Furthermore, our framework treats the user-item interaction in a different way, which is simple and reasonable. Experiment results show a great potential of our model compared to some state-of-the-art algorithms.</p>
<h2 id="V-Acknowledgement"><a href="#V-Acknowledgement" class="headerlink" title="V. Acknowledgement"></a>V. Acknowledgement</h2><p>&emsp;&emsp;This research was supported by the Research Support Scheme of the Ministry of Science and Technology, grant no. MOST 106-2221-E-415-019-MY3.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><blockquote>
<p>[1]   C.-K. Hsieh, L. Yang, Y. Cui, T.-Y. Lin, S. Belongie, and D. Estrin, “Collaborative metric learning,” in Proceedings of the 26th International Conference on World Wide Web, 2017.</p>
</blockquote>
<blockquote>
<p>[2]   F. Schroff, D. Kalenichenko, and J. Philbin, “Facenet: a unified embedding for face recognition and clustering,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015.</p>
</blockquote>
<blockquote>
<p>[3]     B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, “Item-based collaborative filtering recommendation algorithms,” in Proceedings of the 10th International Conference on World Wide Web, 2001. </p>
</blockquote>
<blockquote>
<p>[4]     Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization techniques for recommender systems,” Computer, vol. 42, no. 8, p. 30–37, 2009. </p>
</blockquote>
<blockquote>
<p>[5]     X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T.-S. Chua, “Neural collaborative filtering,” in Proceedings of the 26th International Conference on World Wide Web, 2017. </p>
</blockquote>
<blockquote>
<p>[6]     S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme, “BPR: bayesian personalized ranking from implicit feedback,” arXiv preprint arXiv:1205.2618, 2012. </p>
</blockquote>
<blockquote>
<p>[7]     I. Bayer, X. He, B. Kanagal, and S. Rendle, “A generic coordinate descent framework for learning from implicit feedback,” in Proceedings of the 26th International Conference on World Wide Web, 2017. </p>
</blockquote>
<blockquote>
<p>[8]     X. He, H. Zhang, M.-Y. Kan, and T.-S. Chua, “Fast matrix factorization for online recommendation with implicit feedback,” in Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2016. </p>
</blockquote>
<blockquote>
<p>[9]     M. J. Pazzani and D. Billsus, “Content-based recommendation systems,” Springer, 2007, p. 325–341.</p>
</blockquote>
<blockquote>
<p>[10]     P. Resnick and H. R. Varian, “Recommender systems,” Communications of the ACM, vol. 40, no. 3, p. 56–58, 1997. </p>
</blockquote>
<blockquote>
<p>[11]     F. M. Harper and J. A. Konstan, “The movielens datasets: history and context,” ACM Transactions on Interactive Intelligent systems (tiis), vol. 5, no. 4, p. 1–19, 2015. </p>
</blockquote>
<blockquote>
<p>[12]     K. Järvelin and J. Kekäläinen, “Cumulated gain-based evaluation of IR techniques,” ACM Transactions on Information Systems (TOIS), vol. 20, no. 4, p. 422–446, 2002. </p>
</blockquote>
<blockquote>
<p>[13]     R. Caruana, S. Lawrence, and C. L. Giles, “Overfitting in neural nets: backpropagation, conjugate gradient, and early stopping,” in Advances in Neural Information Processing Systems, 2001. </p>
</blockquote>
<blockquote>
<p>[14]     D. P. Kingma and J. Ba, “Adam: a method for stochastic optimization,” arXiv preprint arXiv:1412.6980, 2014. </p>
</blockquote>
<blockquote>
<p>[15]     M. Carvalho, R. Cadène, D. Picard, L. Soulier, N. Thome, and M. Cord, “Cross-modal retrieval in the cooking context: learning semantic text-image embeddings,” in The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, 2018. </p>
</blockquote>
<blockquote>
<p>[16]     S. Ding, L. Lin, G. Wang, and H. Chao, “Deep feature learning with relative distance comparison for person re-identification,” Pattern Recognition, vol. 48, no. 10, p. 2993–3003, 2015. </p>
</blockquote>
</div><div class="article-licensing box"><div class="licensing-title"><p>tcse-2020</p><p><a href="http://stankisapig.github.io/2021/12/26/tcse-2020/">http://stankisapig.github.io/2021/12/26/tcse-2020/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>stank</p></div></div><div class="level-item is-narrow"><div><h6>發表於</h6><p>2021-12-26</p></div></div><div class="level-item is-narrow"><div><h6>更新於</h6><p>2022-01-07</p></div></div><div class="level-item is-narrow"><div><h6>許可協議</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/TCSE/">TCSE</a></div><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_telegram"></a><a class="a2a_button_whatsapp"></a><a class="a2a_button_reddit"></a></div><script src="https://static.addtoany.com/menu/page.js" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/01/01/scenery-fo-america-week2/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">scenery-fo-america-week2</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/12/25/scenery-of-america/"><span class="level-item">scenery-of-america</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">評論</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://stankisapig.github.io/2021/12/26/tcse-2020/';
            this.page.identifier = '2021/12/26/tcse-2020/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'stanleys-blog' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/myphoto.jpg" alt="Stanley&#039;s Blog"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Stanley&#039;s Blog</p><p class="is-size-6 is-block">Work hard, play Hard!</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Taipei, Taiwan</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分類</p><a href="/categories"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">標籤</p><a href="/tags"><p class="title">4</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/stankisapig" target="_blank" rel="noopener">追蹤</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/stankisapig"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">文章目錄</h3><ul class="menu-list"><li><a class="level is-mobile" href="#TCSE-2020-Learning-to-Rank-for-Collaborative-Filtering"><span class="level-left"><span class="level-item">1</span><span class="level-item">TCSE-2020 Learning to Rank for Collaborative Filtering</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#前言"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">前言</span></span></a></li><li><a class="level is-mobile" href="#Motivation"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Motivation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#I-Introduction"><span class="level-left"><span class="level-item">2</span><span class="level-item">I. Introduction</span></span></a></li><li><a class="level is-mobile" href="#II-Background"><span class="level-left"><span class="level-item">3</span><span class="level-item">II. Background</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#A-Feedbacks"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">A. Feedbacks</span></span></a></li><li><a class="level is-mobile" href="#B-Triplet-Loss"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">B. Triplet Loss</span></span></a></li><li><a class="level is-mobile" href="#C-Collaborative-Filtering-CF"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">C. Collaborative Filtering (CF)</span></span></a></li><li><a class="level is-mobile" href="#D-Leave-one-out"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">D. Leave-one-out</span></span></a></li></ul></li><li><a class="level is-mobile" href="#III-The-Proposed-Medel"><span class="level-left"><span class="level-item">4</span><span class="level-item">III. The Proposed Medel</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#A-Preprocessing"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">A. Preprocessing</span></span></a></li><li><a class="level is-mobile" href="#B-Interaction-Matrix"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">B. Interaction Matrix</span></span></a></li><li><a class="level is-mobile" href="#C-Embedding-Layer"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">C. Embedding Layer</span></span></a></li><li><a class="level is-mobile" href="#D-Optimization-and-Learning"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">D. Optimization and Learning</span></span></a></li><li><a class="level is-mobile" href="#E-New-Leave-one-out"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">E. New Leave-one-out</span></span></a></li></ul></li><li><a class="level is-mobile" href="#IV-Performance-Evaluation"><span class="level-left"><span class="level-item">5</span><span class="level-item">IV. Performance Evaluation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#A-Datasets-and-Environment"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">A. Datasets and Environment</span></span></a></li><li><a class="level is-mobile" href="#B-Baselines-and-Evaluation-Protocol"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">B. Baselines and Evaluation Protocol</span></span></a></li><li><a class="level is-mobile" href="#C-Implement-Details"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">C. Implement Details</span></span></a></li><li><a class="level is-mobile" href="#D-Experimental-Results"><span class="level-left"><span class="level-item">5.4</span><span class="level-item">D. Experimental Results</span></span></a></li></ul></li><li><a class="level is-mobile" href="#V-Conclusion"><span class="level-left"><span class="level-item">6</span><span class="level-item">V. Conclusion</span></span></a></li><li><a class="level is-mobile" href="#V-Acknowledgement"><span class="level-left"><span class="level-item">7</span><span class="level-item">V. Acknowledgement</span></span></a></li><li><a class="level is-mobile" href="#References"><span class="level-left"><span class="level-item">8</span><span class="level-item">References</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">連結</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分類</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/studies/"><span class="level-start"><span class="level-item">studies</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%97%A5%E8%A8%98/"><span class="level-start"><span class="level-item">日記</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%97%A5%E8%A8%98/Scenery-of-America/"><span class="level-start"><span class="level-item">Scenery of America</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%AD%86%E8%A8%98/"><span class="level-start"><span class="level-item">筆記</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%AD%86%E8%A8%98/RS/"><span class="level-start"><span class="level-item">RS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">彙整</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">一月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">十二月 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="訂閱"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2022/01/01/scenery-fo-america-week2/"><img src="/gallery/thumbnails/american/kakashi.jpg" alt="scenery-fo-america-week2"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-01-01T17:54:42.000Z">2022-01-01</time></p><p class="title"><a href="/2022/01/01/scenery-fo-america-week2/">scenery-fo-america-week2</a></p><p class="categories"><a href="/categories/%E6%97%A5%E8%A8%98/">日記</a> / <a href="/categories/%E6%97%A5%E8%A8%98/Scenery-of-America/">Scenery of America</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/12/26/tcse-2020/"><img src="/gallery/thumbnails/tcse-2020/TCSE_title.jpg" alt="tcse-2020"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-12-26T21:44:09.000Z">2021-12-26</time></p><p class="title"><a href="/2021/12/26/tcse-2020/">tcse-2020</a></p><p class="categories"><a href="/categories/studies/">studies</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/12/25/scenery-of-america/"><img src="/gallery/thumbnails/american/sfo.jpg" alt="scenery-of-america"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-12-25T14:48:21.000Z">2021-12-25</time></p><p class="title"><a href="/2021/12/25/scenery-of-america/">scenery-of-america</a></p><p class="categories"><a href="/categories/%E6%97%A5%E8%A8%98/">日記</a> / <a href="/categories/%E6%97%A5%E8%A8%98/Scenery-of-America/">Scenery of America</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-12-21T10:00:54.000Z">2021-12-21</time></p><p class="title"><a href="/2021/12/21/master-thises/">master-thises</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/12/03/rs-note-01/"><img src="/gallery/thumbnails/Hybrid_RS.PNG" alt="Note-Recommender System"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-12-03T09:10:19.000Z">2021-12-03</time></p><p class="title"><a href="/2021/12/03/rs-note-01/">Note-Recommender System</a></p><p class="categories"><a href="/categories/%E7%AD%86%E8%A8%98/">筆記</a> / <a href="/categories/%E7%AD%86%E8%A8%98/RS/">RS</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">標籤</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Diary/"><span class="tag">Diary</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RS/"><span class="tag">RS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recommender-Systems/"><span class="tag">Recommender Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TCSE/"><span class="tag">TCSE</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/marijuana.png" alt="Staley&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 stank</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-TW");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到頁首" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此網站使用Cookie來改善您的體驗。",
          dismiss: "知道了！",
          allow: "允許使用Cookie",
          deny: "拒絕",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="請輸入關鍵字..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"請輸入關鍵字...","untitled":"(無標題)","posts":"文章","pages":"頁面","categories":"分類","tags":"標籤"});
        });</script></body></html>