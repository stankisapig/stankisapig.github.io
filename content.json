{"pages":[{"title":"","text":"","link":"/about/index.html"}],"posts":[{"title":"Note-Recommender System","text":"Collaborative Filtering(協同過濾)approach使用&quot;wisdom of the crowd&quot;推薦物品 基本假設與想法 1.對於商品的ratings(implicitly or explicitly隱性或顯性) 2.客戶過去對某些商品有喜好，未來也會有相同的喜好 3.(網頁停留時間、點擊率) Input 使用者對商品的rating(很多使用者的ratings形成矩陣[user-item矩陣]) Output使用者喜歡或討厭那些商品 可預測每商品分數--推薦Top N個商品 以使用者為基礎的CF(User-based nearest-neighbor collaborative filtering)考慮: 1.相似度如何評估2.考慮多少鄰居 3.如何透過鄰居之分數來預測 目標使用者(active user)A: 透過相似的使用者(peers/nearest neighbor)來推薦與預測A喜歡的商品 用相似使用者之平均來預測是否A會喜歡商品 etc. Measuring user similarityPearson correlation(機率範圍介於-1到1) 與較相似的使用者權重可能會相當 Improve the metrics/prediction function 不一定每個neighbor的rate都為equally &quot;valuable&quot; 偏好不同導致 解決:變異度高的給權重高 case amplification 相似客戶與目標客戶相似度太高，將其權重放大 neighborhood selection 調整鄰居的數目 Content-based通常推薦text documents，如網頁、新聞需求:內容content、喜好preferences 目標:學習user之preferences，找到推薦用戶喜好&quot;相似&quot;的item Knowledge-basedConstraint-based約束(基於明確的推薦規則)找出需求後，看那些商品符合這些requirement 從這些條件找出能滿足最大條件的商品 Case-based(基於不同類型的相似性度量)如果與使用者需求不符 叫使用者改變需求 使用者自己去訂製(違背推薦系統) 使用者有特定需求，則推薦系統推薦有這種條件之物品 requirement都會有不同的權重(例如:買手機有些人一定要求相機要好) 解決:1.CSP (Constraint satisfaction Problem) 此問題可描述為(V, D, C) V: is a set of variables D: is a set of finite domains for these variables,and C: is a set of constraints that describes the combinations of values that variables can simultaneously take. 用crossover logic可解決 2.Conjunctive query Hybrid recommender systems共分別為下列三種 Parallel use of several systemsMonolithic exploiting different featuresPipelined invocation of different systems Feature combination strategy 可以用CF來推薦 但透過資料可以觀察到其他user items的偏好 再過濾出要推薦的商品 AI期刊：AAAI、IJCAI、AAMAS CVPR、ICCR、ECCR、ICML、ICLR、ACML、NIPS","link":"/2021/12/03/rs-note-01/"},{"title":"master-thises","text":"","link":"/2021/12/21/master-thises/"},{"title":"scenery-of-america","text":"Scenery of America-First WeekDay 1 - 2021.12.24這是我第一次來美國。上午11點帶著期待從桃園機場出發，到達舊金山時是24號上午6點，感覺上這一天有40個小時可以過，真的很神奇。聯合航空整體來說服務還算是挺好的，讓我印象比較深刻的是這次搭機只有50幾位乘客，我們每位乘客都可以有自己的一排，甚至在休息時可以直接在3至4個位置上躺下；還有他們的App算是讓我比較喜歡的，可以直接用他們的App來使用entertainment的所有項目。 Jake接到我們之後有去看金門大橋，回家我們後幫忙Patty用擀麵棍製作些手工藝，之後實在是撐不住就小睡了一覺。 起來後我們一起到Jake的外婆家慶祝聖誕節，大家人都非常nice，除了餅乾沙拉以外，我們吃了些像是玉米粥的東西還有咖哩飯，吃完飯後我們一起玩了些團康遊戲(Trivia, Hands Up)；外國的平安夜就跟台灣的農曆新年很像，家人們會聚在一起吃喝聊天，這次在美國過聖誕節氣氛很好，對我來說是個非常新鮮的體驗。 Day 2 - 2021.12.25第二天半夜四點多就醒來了，時差還沒有完全調整好。上午寫完我的Blog之後Jake找我一起去7-11買飲料，跟台灣挺不一樣的，有非常多的Monster Energy，Jake抓了幾瓶；我則選擇了一瓶Mountain Dew。回到家後Katie跟Clare已經在忙著做早餐，姊跟我說他們各個都是三明治專家；這三明治也真的超好吃，其內容物包含：酪梨、番茄、培根、蛋，我聽他們說這叫做American Scone。 中午時我們完成了昨天的手工藝品，Tom帶我去倉庫用圓鋸機把擀麵棍上方鉅出一條縫，好讓吸附磁鐵的鐵片可以嵌進去。Tom說它將會放在外婆家外當作裝飾品。 晚餐時間，大家今天聚在Tom家慶祝聖誕節，今天吃了沙拉、烤肉、燻火腿、馬鈴薯泥還有一道烤洋蔥豆子，我特別覺得豆子這道超級好吃，我吃完的時候直接痛哭流涕。 晚餐時間過後，大家在拍了大合照之後，Tom發給大家聖誕襪，裡面有美金以及口袋懷錶！ 在這之後我們進行了聖誕節的遊戲，我們將拆掉一個很大的保鮮膜球！這個保鮮膜球裡面捆了非常多的禮物，遊戲玩法是：大家會圍成一圈，保鮮膜球輪流傳給大家拆，骰子也是大家輪流骰，直到有人骰出Doubles才會將保鮮膜球傳給下一位，在還沒有人骰出Doubles的時候你都可以瘋狂的拆這顆禮物！昨天聽到Joe稱這顆球為Chaos，非常搞笑。我拿到了一個防水袋、一包電池、隨身充、魚餌、還有一根鹿角造型的鉛筆(整枝都是鉛筆)。 拆完禮物後，大家一起玩了Trivcia以及你畫我猜，直到累了回房間休息。第二天有比較身處於美國這件事情了，雖說跟大家對話還不是很流利，但是姊姊會幫助我，也在各種與大家互動的遊戲中得到了很多的練習。祝福各位聖誕快樂！ Day 3 - 2021.12.26今天上午跟Jake、Clare還有姐姐去吃了當地的早餐（Sunshine Cafe），我點了第一個在美國吃到的漢堡搭配番茄沙拉，整體來說是非常不錯的，黑咖啡也是可以一直續杯的。 吃完飯後跟Tom一家一起去逛了Barnes &amp; Noble還有REI，前者有點像是台灣的誠品，我在音樂區跟電腦科學區逛了很久，可惜沒有找到喜歡的書；後者像是體育用品店，賣了很多諸如登山、露營的用品與衣著，我在那邊買到一件不錯的背心以及一個軟包，很期待以後旅遊或是露營可以用到它們。 下午我們在家中與Jake的Cousin一起聚會，有非常多的小孩，大家都在聊天以及玩小孩玩狗，我則是坐在沙發上看美式足球，持續享受這這聖誕節的氣氛，大家也會到廚房完成自己想吃的三明治並且把他烤到你喜歡的程度，我覺得非常棒。 晚上時我們與Jake一家去玩了密室脫逃，是一個很棒的體驗，也是我第一次嘗試密室逃脫，超出我以前所想像的有趣。回到家後大家玩了drinking games，這遊戲稱之為baseball，的我們分成了兩組，在桌上兩隊都會有四個杯子排成一排，丟進這四個杯子的意義由近至遠就是一壘至全壘打；以及六個杯子分別代表兩隊的壘包。同時當你在壘包上、你可以選擇快速的喝一口酒，之後開始跟你隔壁隊壘包的防守員PK把杯子從倒立變成正立，功方獲勝代表盜壘成功，反之則出局。 第三天在這邊慢慢觀察到些美國生活的特別之處，好比加州是可以紅燈右轉的除非有告示牌制止；在自家門前傳接美式足球是一件很正常的事情；每個人在這邊都很進入狀況，都很認真的在生活。 Day 4 - 2021.12.27上午從一個平凡的美式早餐開始，大家吃著cereal搭配咖啡還有柳橙。今天上午的行程Tom帶著大家前往Berkeley，我們首先來到UC Berkeley，天氣不是很好所以並沒有拍了很多照片，比較可惜的是沒有拍到Sather Tower的照片。這是我第一次參觀美國的學校，覺得環境還是挺不錯的，有點像是高配版的台灣大學學校。 繞完學校後我們到附近的Berkeley Rose Garden轉轉，是個風景很美的地方，從遠處也可以看見SFO。大家在一旁的滑梯玩了一陣子，非常開心，而當然剛剛說天氣不好地板非常濕，所以玩完滑梯的同時我們的褲子也都濕掉了。 離開之後我們到Berkeley Waterfront走了一圈，這時天氣已經放晴，也在此停留一陣子並且拍了許多照片，隔著SFO Bay看過去的景色還算是非常令人驚豔的。 中午的時候我們在Avalon Public Market吃中餐，大致上像是一個高級的美食街？裡面有賣許多料理，包含拉麵、韓式烤肉、咖哩等，我則是點了Tacos。吃飽回程途中我們有經過Pixar，可惜的是只能從外面瞥見裡面的Pixar球跟檯燈，並沒有開放參觀。 Day 5 - 2021.12.28今天上午從Starbucks開始，展開奇妙的一天。上午Tom帶上我跟Jake還有Joe一起去採買磚塊，為的是要去幫外婆家新蓋的紡織屋鋪磚塊，我們在Lowe’s(美國的五金行)買到磚塊，這磚塊大概是30幾磅，所以今天我有很足夠的運動量。 外婆很開心我們能來幫忙，她笑得非常開心，我也很期待這項任務完成的那天！值得一提的是，外婆家的院子充滿狗屎，今天是我的Stan Smith最骯髒的一天。外婆家在Pittsburgh，那邊是個好地方，有許多小山丘，在那邊生活的人看起來都很Chill。 中午我跟Jack一起到Southern Comfort買午餐，我們吃了些漢堡、穀物等，其實這幾天吃下來我覺得美國的食物還算是蠻重口味的而且偏乾，總是會想在吃飯時多喝點水。 晚上的時候，我跟Jake幫忙姊搬家，到她即將入住的地方(Sunnyvale)，附近看起來挺方便的，姊的室友Julie人也非常nice，祝福之後她在那邊的生活與工作能一切順利。 在那之後我們也到姊搬家期間Waymo提供給她的住處看了一下，我的感想是，選對公司很重要，並且這種福利跟台灣公司真的沒辦法做比較。來到美國已經第五天，從一些細節上，讓我覺得在這生活是一件非常棒的事情。 Day 6 - 2021.12.29還記得Tom家前的枯樹嗎？今天上午，Tom跟我還有Jake一起把他給砍了！我們大概花了三四個多小時，反覆的把土挖出來並且鉅掉根。最後是用車子後方與樹的頂端綁上繩子把樹拉倒的，這一切都太瘋狂了，我從來沒做過種種事情。 我們在復原完畢後鋪上了兩大袋的草木灰，除了我的外套跟牛仔褲髒透了以外，一切就像甚麼都沒發生一樣。 在那之後的午餐我非常餓，我把一個很巨大的漢堡給吃掉了。 晚上的時候我跟姊還有Jake一起去Scott家玩PathFinders。其實我在來美國之前很少嘗試著大家一起玩桌遊，一部份的原因是因為那些看似非常複雜的設定，另外我也非常懶得去了解它，但我能說它真的很好玩，而且Scott是個很有趣的人，它把遊戲形容得繪聲繪影，就像出門前我問姊我們是要去玩甚麼遊戲時她回答的一樣：想像遊戲。當然我聽到姊跟我這麼說的時候我的表情長這樣？_？ Day 7 - 2021.12.30San Francisco.過了Oakland Bay Brudge我們首先到了Coit Tower從高處享受著被SFO吞噬的感覺，通往Coit Tower頂端我們需要搭乘一個很復古的電梯，相當有特色。 在那之後我們來到Pier 39，是漁人碼頭這邊的一個旅遊中心、購物景點，除了有很多小店以外，很有特色的是那邊有以個海洋哺乳動物中心，旁邊的平台上全是海獅。中午時我們也在那邊的Bistro用餐，我點了很有特色的Boudin Sourdough Breadbowl，這個份量真的是大的可怕，吃完後有後悔沒有點Petite。 在碼頭逛完之後我們去看了Golden Gate Bridge，這景象真的非常壯觀，這可能就是來到舊金山的感受。 最後我們來到唐人街，裡面夾雜著許多日本、韓國、中國的店，挺新鮮的，雖說讓邊的交通讓我感受到美國的大都市的擁擠以及緊湊的氣氛，我並沒有很喜歡。舊金山還有一大特色是，街道真的非常的長直，並且是在大斜波上面，從車上或是街道上，你都可以看到遠處的街景。 晚上姊幫大家點了BBQ一起吃，這週真的非常感謝Tom一家人可以這麼的照顧我還有姊，雖然我總是很害羞，但他們都非常有耐心的與我溝通，在未來我也非常歡迎你們來台灣玩。","link":"/2021/12/25/scenery-of-america/"},{"title":"tcse-2020","text":"TCSE-2020 Learning to Rank for Collaborative Filtering前言這是一篇關於我在Mars Lab時發表於TCSE-2020的論文，首先要感謝邱志義教授以及學長Benny與我的partner Jim，總是在研究上給我許多的幫助以及啟發。這是一篇關於推薦系統的論文，有興趣的夥伴歡迎交流指教。 Motivation推薦系統現在廣泛應用於各個領域甚至是我們生活之中，其中有兩大要素啟發了我們這次的實驗。第一： 為了實現推薦系統，我們可以很直觀地認為系統應推薦符合用戶期望的物品。然而，給定一組物品，過去的研究時常專注於“相關”或“不相關”的某些物品，而不是專注於物品對之間的偏好程度。這可能違反推薦系統的主要目的。第二： leave-one-out evaluation protocol被廣泛應用如下： 對於每個用戶，他們保留他/她最近的交互作為測試集，並利用剩餘的數據進行訓練。由於在評估過程中為每個用戶對所有項目進行排序太耗時，他們遵循通用策略，隨機抽取 100 個用戶未交互的項目，在 100 個項目中對測試項目進行排名。但是，每個用戶最近的交互項可能是也可能不是他們喜歡的，有可能用戶對最新項的真實評分很低，不應該被系統推薦；它會與評估設置的設計相衝突。 I. Introduction&emsp;&emsp;The recommendation system is used to predict the user’s “rating” or “preference” of items and can help people cope with complex preferences prediction problems. Collaborative filtering approaches build a model from a user’s past behavior (items previously purchased or numerical ratings given to those items) as well as similar decisions made by other users. This model is then used to predict or rate items that the user may have an interest in. Content-based filtering approaches utilize a series of discrete, pre-tagged characteristics of an item in order to recommend additional items with similar properties. &emsp;&emsp;In 2017, Hseih et al. [1] proposed the collaborative metric learning (CML) which revealed the potential of inner product to model user-item relationships. They argued that the inner product violates the triangle inequality which is essential to model the fine-grained preference of users. Thus, the authors come up with a metric-based learning scheme that minimizes the distance between user and item vectors of positive interactions. Simultaneously, this scheme also learns user-user similarity and item-item similarity in the latent space. Their work demonstrates a highly competitive performance on many benchmark datasets. &emsp;&emsp;However, in spite of the success of these works, they consist some weaknesses. Firstly, for implementing a recommender system, it is intuitively to consider that the system recommends the item that fits the expectation of the user. However, given a set of objects, they focus on the certain pairs of objects that are “relevant” or “irrelevant” instead of knowing the preference degree between pairs of objects. It may violate the main purpose of the recommender system. Secondly, the leave-one-out evaluation protocol is widely adopted as follows: For each user, they held-out his/her latest interaction as the test set and utilized the remaining data for training. Since it is too time-consuming to rank all items for every user during evaluation, they follow the common strategy that randomly samples 100 items that are not interacted by the user, ranking the test item among the 100 items. However, the latest interaction item of each user may or may not be the one they prefer, it is possible that the true rating of the latest item rated by the user is low, and should not be recommended by the system; it will conflict the design of the evaluation setup. &emsp;&emsp;To solve the above problem, we propose a novel collaborative metric learning method with respect to the traditional collaborative filtering, which learns a metric space to represent not only the user’s preferences but also their similarities. We employ the triplet loss function in neural networks to train users’ preference ranking model. We care more about user preferences than whether users interact with the item. Moreover, we come up with a new leave-one-out evaluation methodology. Rather than using his/her latest interaction as the test set, we hold-out one highest rated item of each user according to the true ratings then randomly samples 100 items that are not interacted by the user, ranking the test item among the 100 items. This new methodology can retrieve the relevant item for the user and eliminate the conflict in the original evaluation. Experiment results show a great potential of our model compared to some state-of-the-art algorithms. &emsp;&emsp;The remainder of this paper is organized as follows. In Section II, we introduced the background used in this paper. In Section III, we introduce our novel collaborative matric learning model. In Section IV, we compare our method to some state-of-the-art algorithms on MovieLens dataset. Finally, we conclude this paper in Section V. II. BackgroundA. Feedbacks&emsp;&emsp;In order to implement a recommender system, it requires substantial data provided by the user purposely or unpurposely, also known as feedbacks. Feedbacks can be divided into the explicit feedback and implicit feedback by the differences of its essence. &emsp;&emsp;The explicit feedback directly shows the preferences of user, according to the opinion or score given to the item, usually formed as measurable indicators. Comparing to the explicit feedback, the implicit feedback is relatively blurry, it could be any slight action that user makes (e.g., clicks, browse, bookmarks). The definition of the implicit feedback can be described as follows: $$ y_{ui} =\\left\\{ \\begin{aligned} &1,if \\quad interaction < user_u, item_i > exist\\\\ &0, otherwise \\end{aligned} \\right. $$ where Y is the user-item interaction matrix. &emsp;&emsp;Note that for the implicit feedback, a value of 0 does not necessarily imply negative feedback. In most cases, the user is unaware of the existence of the item and this forms the keystone of the recommendation problem, i.e., if the user did not rate an item or have no interaction with an item, we can’t be sure the relation between them. B. Triplet Loss&emsp;&emsp;Triplet loss [2] is a widely used loss function in solving the optimization problem, it is even used to accomplish information retrieval tasks within different modalities in recent studies. Over all, triplet loss is a fine mapping technique and a good way to compute loss in the field of pattern recognition and cluster analysis. Figure 1 shows how triplet works. &emsp;&emsp;Triplet includes an anchor point, a positive point and a negative point. Through an embedding architecture, inputs are embedded onto the new vector space, where the embedded result follows the triplet loss concept. During the learning phase, the positive point will be pulled toward the anchor point while the negative point will be push away from the anchor point. Note that in our work, the anchor point indicates the user, positive point indicates the item that user prefers more and the negative point indicates the item that user prefers less. Figure 2 and Figure 3 show the embedded status before and after the learning. C. Collaborative Filtering (CF)&emsp;&emsp;Traditional CF algorithms [3] are based on the user similarity computed by heuristic, such as cosine similarity. Recommendations are made by aggregating the ratings of k-nearest users. Matrix factorization (MF) [4] has been the most popular CF approach for a decade due to its remarkable performance. The original MF models are designed to model users’ feedback by mapping users and items to a latent space, such that user-item relationships can be inferred through their dot product in this latent space. To be more precise, let $$r_jk$$ denote user j‘s rating to item k, we learn user vector $$u_j$$ and item vector $$i_k$$ such that their dot product $$u^T_j i_k$$ approximate $$r_{jk}$$ through the following formula: $$ y_{ui} =\\left\\{ \\begin{aligned} &1,if \\quad interaction < user_u, item_i > exist\\\\ &0, otherwise \\end{aligned} \\right. $$","link":"/2021/12/26/tcse-2020/"},{"title":"scenery-fo-america-week2","text":"Scenery of America-Second WeekDay 8 - 2021.12.31上午，Jake帶著我還有姊來去逛傢俱，為姊未來的住處提前作準備，首先我們看了一些擺設於房間、餐廳的傢俱，姊只是先把規格拍下，或許等到當地或是完成樣式比價等再做決定，之後我們去買了Mattress，姊挑了一組含兩個枕頭的床墊，我覺得這花得很值得，因為我也算是個很注重生活品質的人，很開心她選到了一個很不錯的床墊。 下午我們待在外婆家，一起玩桌遊還有吃外婆煮的濃湯，濃湯真的超好喝，蛤蜊濃湯與生蠔濃湯兩種我都嘗試了，雖說還是覺得生蠔的味道很腥，但是他們都超棒的，過了一個悠閒的玩狗玩桌遊吃吃餅乾點心的下午。 從外婆家回Tom家的途中，我們買了些啤酒，準備吃晚餐，我餐我們叫了些台灣菜來吃，我能說這真的是台灣人開的餐廳，因為不是台灣人不可能弄出這麼好吃的炒飯，大家在歡樂的氣氛當中一起遊玩，等待新年的到來。 新的一年對自己也有許多的期許，希望自己能變得更有自信、希望自己可以迎接每項挑戰。期許家人能夠一切平安，事事順心。或許2021稱不上是一個很棒的一年，這年當中，我完成了我的碩士學位、服完兵役，結束了一段四年半的感情，但同時也新交了許多志同道合的好友，從他們身上學習到了許多新事物。最後，期許新的一年能過上自己所嚮往的生活，感謝身邊的一切人、事、物。新年快樂！","link":"/2022/01/01/scenery-fo-america-week2/"}],"tags":[{"name":"RS","slug":"RS","link":"/tags/RS/"},{"name":"Recommender Systems","slug":"Recommender-Systems","link":"/tags/Recommender-Systems/"},{"name":"Diary","slug":"Diary","link":"/tags/Diary/"},{"name":"TCSE","slug":"TCSE","link":"/tags/TCSE/"}],"categories":[{"name":"筆記","slug":"筆記","link":"/categories/%E7%AD%86%E8%A8%98/"},{"name":"RS","slug":"筆記/RS","link":"/categories/%E7%AD%86%E8%A8%98/RS/"},{"name":"日記","slug":"日記","link":"/categories/%E6%97%A5%E8%A8%98/"},{"name":"Scenery of America","slug":"日記/Scenery-of-America","link":"/categories/%E6%97%A5%E8%A8%98/Scenery-of-America/"},{"name":"studies","slug":"studies","link":"/categories/studies/"}]}